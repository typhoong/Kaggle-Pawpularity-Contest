{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ccfc2e",
   "metadata": {
    "id": "HB6tcaFW_H3T",
    "papermill": {
     "duration": 0.022571,
     "end_time": "2021-11-28T13:25:02.216142",
     "exception": false,
     "start_time": "2021-11-28T13:25:02.193571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc9d2d7",
   "metadata": {
    "id": "qwvvNvo_2LH5",
    "papermill": {
     "duration": 9.927229,
     "end_time": "2021-11-28T13:25:12.217576",
     "exception": false,
     "start_time": "2021-11-28T13:25:02.290347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from box import Box\n",
    "from timm import create_model\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import optuna, datetime\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.progress import ProgressBarBase\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "# from pytorch_lightning.loggers import WandbLogger\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import wandb\n",
    "import cv2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "import shutil\n",
    "import pickle\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torch.utils.data import TensorDataset\n",
    "import time\n",
    "import gc\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387422c-481e-49ef-a352-dca95deb9584",
   "metadata": {},
   "source": [
    "# Meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4813213",
   "metadata": {
    "id": "spieGAU32LH6",
    "papermill": {
     "duration": 0.02556,
     "end_time": "2021-11-28T13:25:12.306938",
     "exception": false,
     "start_time": "2021-11-28T13:25:12.281378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drive_root = '..'\n",
    "TRAIN_DIR = f\"{drive_root}/input/petfinder-pawpularity-score/train\"\n",
    "TEST_DIR = f\"{drive_root}/input/petfinder-pawpularity-score/test\"\n",
    "DENSE_FEATURES = [\n",
    "    'Subject Focus',\n",
    "    'Eyes',\n",
    "    'Face',\n",
    "    'Near',\n",
    "    'Action',\n",
    "    'Accessory',\n",
    "    'Group',\n",
    "    'Collage',\n",
    "    'Human',\n",
    "    'Occlusion',\n",
    "    'Info',\n",
    "    'Blur',\n",
    "    'img_long_axis'\n",
    "]\n",
    "df_train = pd.read_csv(f\"{drive_root}/input/petfinder-pawpularity-score/train.csv\")\n",
    "df_test = pd.read_csv(f\"{drive_root}/input/petfinder-pawpularity-score/test.csv\")\n",
    "df_train['filepath'] = df_train.Id.apply(lambda x :f\"{TRAIN_DIR}/{x}.jpg\" )\n",
    "df_test['filepath'] = df_test.Id.apply(lambda x :f\"{TEST_DIR}/{x}.jpg\" )\n",
    "\n",
    "long_axis_df_path = f\"{drive_root}/input/pet-train-long-axis/df_train_w_long_axis.csv\"\n",
    "long_axis_max = 1280\n",
    "if os.path.isfile(long_axis_df_path):\n",
    "    df_train = pd.read_csv(long_axis_df_path)\n",
    "else:\n",
    "    df_train['img_long_axis'] = df_train.Id.apply(lambda x : max(cv2.imread(f\"{TRAIN_DIR}/{x}.jpg\" ).shape[:2]))\n",
    "    df_train['img_long_axis'] /=long_axis_max\n",
    "    df_train['img_long_axis'] = df_train['img_long_axis'].astype(np.float32)\n",
    "    df_train['filepath'] = df_train.Id.apply(lambda x :f\"{TRAIN_DIR}/{x}.jpg\" )\n",
    "    \n",
    "df_test['img_long_axis'] = df_test.Id.apply(lambda x : max(cv2.imread(f\"{TEST_DIR}/{x}.jpg\" ).shape[:2]))\n",
    "df_test['img_long_axis'] /=long_axis_max\n",
    "df_test['img_long_axis'] = df_test['img_long_axis'].astype(np.float32)\n",
    "df_test['filepath'] = df_test.Id.apply(lambda x :f\"{TEST_DIR}/{x}.jpg\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6320d447-7937-4f9f-9a63-f486652d8690",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11894965",
   "metadata": {
    "id": "5TZT70L4pi4u",
    "papermill": {
     "duration": 0.027435,
     "end_time": "2021-11-28T13:25:12.623895",
     "exception": false,
     "start_time": "2021-11-28T13:25:12.596460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BayesianLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        \n",
    "    def forward(self,yhat,y,std):\n",
    "        y = y/100.\n",
    "        ce = self.bce(yhat, y)\n",
    "        inv_std = torch.exp(-std)\n",
    "        mce = inv_std * ce\n",
    "        loss = 0.5 * (mce + std).mean()\n",
    "        return loss\n",
    "    \n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931293fb-0945-4236-92f0-759a86d39768",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b83078de-d634-4523-b37c-25279aed125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y=None):#, image_size=224):\n",
    "        self._X = x\n",
    "        self._y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self._X[idx]\n",
    "        if self._y is not None:\n",
    "            label = self._y[idx]\n",
    "            return feature, label\n",
    "        return feature\n",
    "    \n",
    "class PetfinderDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_features, train_y, val_features, val_y, cfg,):\n",
    "        super().__init__()\n",
    "        self._train_features = train_features\n",
    "        self._val_features = val_features\n",
    "        self._train_y = train_y\n",
    "        self._val_y = val_y\n",
    "        self._cfg = cfg\n",
    "\n",
    "    def __create_dataset(self, train=True):\n",
    "        if train==True:\n",
    "            return CustomDataset(self._train_features, self._train_y)\n",
    "        else:\n",
    "            return CustomDataset(self._val_features, self._val_y)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = self.__create_dataset(True)\n",
    "        return DataLoader(dataset, **self._cfg.train_loader)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = self.__create_dataset(False)\n",
    "        return DataLoader(dataset, **self._cfg.val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735607ae-06c5-46ac-aab6-ec6123c6bf16",
   "metadata": {},
   "source": [
    "# EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5939613b-ab00-4961-9ab5-343c39592d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper():\n",
    "    def __init__(self, patience: int, mode:str)-> None:\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "\n",
    "        # Initiate\n",
    "        self.patience_counter = 0\n",
    "        self.stop = False\n",
    "        self.best_loss = np.inf\n",
    "        \n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        loss = -loss if self.mode == 'max' else loss  # get max value if mode set to max\n",
    "\n",
    "        if loss >= self.best_loss:\n",
    "            # got better score\n",
    "            self.patience_counter += 1\n",
    "            \n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True  # end\n",
    "\n",
    "        elif loss < self.best_loss:\n",
    "            # got worse score\n",
    "            self.patience_counter = 0\n",
    "            self.best_loss = loss\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbffae9-5d1b-4cf7-8715-45e97aa14b01",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d56e0934",
   "metadata": {
    "id": "5FC8MKiq2LH7",
    "papermill": {
     "duration": 0.031668,
     "end_time": "2021-11-28T13:25:12.674744",
     "exception": false,
     "start_time": "2021-11-28T13:25:12.643076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {'seed': 2021,\n",
    "          'root': f\"{drive_root}\", \n",
    "          'n_splits': 10,\n",
    "          'epoch': 1000,\n",
    "          'patience':10,\n",
    "          'train_loader':{\n",
    "              'batch_size': 512,\n",
    "              'shuffle': True,\n",
    "              'num_workers': 1,\n",
    "              'pin_memory': False,\n",
    "              'drop_last': True,\n",
    "          },\n",
    "          'val_loader': {\n",
    "              'batch_size': 512,\n",
    "              'shuffle': False,\n",
    "              'num_workers': 8,\n",
    "              'pin_memory': False,\n",
    "              'drop_last': False\n",
    "         },\n",
    "          'save_discript':'Sigmoid_Bayesian',\n",
    "          'model':{\n",
    "              'name': 'swin_large_patch4_window12_384_in22k',\n",
    "              'img_feature_dim':128,\n",
    "              'output_dim': 1,\n",
    "              'first_drop': 0.5,\n",
    "              'second_drop': 0.5,\n",
    "              'third_drop': 0.5,\n",
    "              'last_drop':0.5,\n",
    "              'activation':'nn.SELU',\n",
    "          },\n",
    "          'optimizer':{\n",
    "              'name': 'optim.AdamW',\n",
    "              'AdamW':{\n",
    "                  'lr': 1e-5,\n",
    "                  'betas': (1,1),\n",
    "                  'weight_decay': 0.01,\n",
    "                  'amsgrad': False,\n",
    "                  \n",
    "                },\n",
    "          },\n",
    "          'scheduler':{\n",
    "              'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
    "              'CosineAnnealingWarmRestarts':{\n",
    "                  'T_0': 4,\n",
    "                  'T_mult':2,\n",
    "                  'eta_min': 1e-7,\n",
    "              }\n",
    "          },\n",
    "          'metric': 'RMSELoss',\n",
    "}\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9087661-3d5c-4dbb-b35f-449342fbf6e7",
   "metadata": {},
   "source": [
    "# Setting arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ae2876e",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1637508005015,
     "user": {
      "displayName": "Daewoo Myoung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyUBzKneZcIle1t7HXIAaL548lK9ndvDFCUhROwQ=s64",
      "userId": "15525163033989858669"
     },
     "user_tz": -540
    },
    "id": "b-nCf5Ze-6im",
    "outputId": "554d312b-fec4-402a-bb40-a442a7824d56",
    "papermill": {
     "duration": 0.029591,
     "end_time": "2021-11-28T13:25:12.872125",
     "exception": false,
     "start_time": "2021-11-28T13:25:12.842534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "seed_everything(config.seed)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "model_code = 'swin_2021'\n",
    "torch.manual_seed(config.seed)\n",
    "torch.cuda.manual_seed(config.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=config.n_splits, shuffle=True, random_state=config.seed)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "activation_list = ['nn.LogSigmoid', 'nn.Hardswish',  'nn.PReLU', 'nn.ReLU', 'nn.ELU', 'nn.ReLU6', 'nn.SELU', 'nn.CELU']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c143f4-61da-45f6-83b3-bdc6a5049995",
   "metadata": {},
   "source": [
    "# Base performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b50b701-da65-4f98-aba2-68ad5d62ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold-0 score : 17.94109932464706\n",
      "fold-1 score : 17.758151860820355\n",
      "fold-2 score : 17.467777698085317\n",
      "fold-3 score : 17.012767763917406\n",
      "fold-4 score : 17.31225062417872\n",
      "fold-5 score : 17.688730475815426\n",
      "fold-6 score : 17.427359306406\n",
      "fold-7 score : 17.744088158710746\n",
      "fold-8 score : 17.460749473536374\n",
      "fold-9 score : 18.109040047630103\n",
      "cv score : 17.59220147337475\n"
     ]
    }
   ],
   "source": [
    "swin_scores = []\n",
    "model_save_dir = f'{drive_root}/output/weights/final_weights/{model_code}/'\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_train[\"Id\"], df_train[\"Pawpularity\"])):\n",
    "    # Split k-fold    \n",
    "    train_df = df_train.loc[train_idx].reset_index(drop=True)\n",
    "    val_df = df_train.loc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # Load embed features\n",
    "    val_predicts = np.load(f'{model_save_dir}val_predicts_fold{fold}.npy')\n",
    "    swin_score = mean_squared_error(val_df.Pawpularity, val_predicts)**0.5\n",
    "    swin_scores.append(swin_score)\n",
    "    print(f'fold-{fold} score : {swin_score}')\n",
    "cv_score = sum(swin_scores) / len(swin_scores)\n",
    "print(f'cv score : {cv_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674e1d2-8811-4d4a-85f7-dcd9d88a77d8",
   "metadata": {},
   "source": [
    "# Define objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9448a483-9966-4eb1-b48b-0091f57a4891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    #Wandb\n",
    "    #ctime = datetime.datetime.now(tz=datetime.timezone(datetime.timedelta(hours=9))).strftime('%y%m%d_%H%M%S')\n",
    "    #wandb.init(config=config, project='SimpleHead-Optuna-Petfinder', entity='kdpark', name=ctime)\n",
    "    \n",
    "    #Set hyperparams\n",
    "    config.optimizer.AdamW.lr = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    config.model.h1 = trial.suggest_categorical('h1', [32, 64, 128, 256, 512, 1024, 2048])\n",
    "    config.model.h2 = trial.suggest_categorical('h2', [32, 64, 128, 256, 512, 1024, 2048])    \n",
    "    config.patience =  trial.suggest_categorical('patience', [20, 30, 50])\n",
    "    config.model.activation = trial.suggest_categorical('activation', activation_list)\n",
    "    config.model.first_drop = trial.suggest_float('first_drop', 0, 0.9)\n",
    "    config.model.second_drop = trial.suggest_float('second_drop', 0, 0.9)\n",
    "    config.model.third_drop = trial.suggest_float('third_drop', 0, 0.9)\n",
    "    \n",
    "    beta1 = trial.suggest_float('beta1', 0, 1)\n",
    "    beta2 = trial.suggest_float('beta2', 0, 1)\n",
    "    config.optimizer.AdamW.betas = (beta1, beta2)\n",
    "    config.optimizer.AdamW.weight_decay = trial.suggest_float('weight_decay', 0, 1)\n",
    "    config.optimizer.AdamW.amsgrad = trial.suggest_categorical('amsgrad', [True, False])\n",
    "    config.scheduler.CosineAnnealingWarmRestarts.T_0 = trial.suggest_int('T_0', 1, 100)\n",
    "    config.scheduler.CosineAnnealingWarmRestarts.T_mult = trial.suggest_int('T_mult', 1, 100)\n",
    "    config.scheduler.CosineAnnealingWarmRestarts.eta_min = trial.suggest_loguniform('eta_min', 1e-10, 1e-5)\n",
    "    swin_scores=[]\n",
    "    val_scores=[]\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df_train[\"Id\"], df_train[\"Pawpularity\"])):\n",
    "        \n",
    "        early_stopper = EarlyStopper(patience = config.patience, mode='min')\n",
    "        val_min_score = 1e+100\n",
    "                \n",
    "        # Split k-fold    \n",
    "        train_df = df_train.loc[train_idx].reset_index(drop=True)\n",
    "        val_df = df_train.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        # Load embed features\n",
    "        val_predicts = np.load(f'{model_save_dir}val_predicts_fold{fold}.npy')\n",
    "        train_embed_features = np.load(f'{model_save_dir}train_embed_org_fold{fold}.npy')\n",
    "        val_embed_features = np.load(f'{model_save_dir}val_embed_org_fold{fold}.npy')\n",
    "        train_embed_flip_features = np.load(f'{model_save_dir}train_embed_flip_fold{fold}.npy')\n",
    "        val_embed_flip_features = np.load(f'{model_save_dir}val_embed_flip_fold{fold}.npy')\n",
    "        train_embed_merge_features = np.load(f'{model_save_dir}train_embed_merge_org_fold{fold}.npy')\n",
    "        val_embed_merge_features = np.load(f'{model_save_dir}val_embed_merge_org_fold{fold}.npy')\n",
    "        train_embed_merge_flip_features = np.load(f'{model_save_dir}train_embed_merge_flip_fold{fold}.npy')\n",
    "        val_embed_merge_flip_features = np.load(f'{model_save_dir}val_embed_merge_flip_fold{fold}.npy')\n",
    "        train_concat_features = np.concatenate((train_embed_merge_features, train_embed_merge_flip_features), axis=0)\n",
    "        train_loader = DataLoader(CustomDataset(train_concat_features, pd.concat([train_df['Pawpularity'], train_df['Pawpularity']]).reset_index(drop=True)), shuffle=config.train_loader.shuffle, batch_size=config.train_loader.batch_size)\n",
    "        swin_score = mean_squared_error(val_df.Pawpularity, val_predicts)**0.5\n",
    "        \n",
    "        # Model\n",
    "        q = nn.Sequential(\n",
    "                nn.Dropout(config.model.first_drop), \n",
    "                nn.Linear(train_concat_features.shape[1], config.model.h1),\n",
    "                eval(config.model.activation)(),\n",
    "                nn.Dropout(config.model.second_drop), \n",
    "                nn.Linear(config.model.h1, config.model.h2),\n",
    "                eval(config.model.activation)(),\n",
    "                nn.Dropout(config.model.third_drop), \n",
    "                nn.Linear(config.model.h2, 1)).to('cuda')\n",
    "        \n",
    "        # Optimizer & scheduler\n",
    "        optimizer = eval(config.optimizer.name)(q.parameters(), **config.optimizer.AdamW)\n",
    "        scheduler = eval(config.scheduler.name)(optimizer, **config.scheduler.CosineAnnealingWarmRestarts)\n",
    "\n",
    "        # Train\n",
    "        for epoch in range(config.epoch):\n",
    "            \n",
    "            q.train()\n",
    "            \n",
    "            train_loss = 0\n",
    "            \n",
    "            for feature, label in train_loader:\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                feature, label = feature.to('cuda') , label.to('cuda')\n",
    "                \n",
    "                pred = q(feature)\n",
    "                \n",
    "                pred = pred.squeeze(dim=-1)\n",
    "                \n",
    "                loss = criterion(pred.squeeze(dim=-1).float(), (label/100.).float())\n",
    "                \n",
    "                try:\n",
    "                    loss.backward()\n",
    "\n",
    "                    optimizer.step()\n",
    "\n",
    "                    scheduler.step()\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                \n",
    "            q.eval()\n",
    "            pred_lst = []\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                org_feature = torch.FloatTensor(val_embed_merge_features).to('cuda')\n",
    "                flip_feature = torch.FloatTensor(val_embed_merge_flip_features).to('cuda')\n",
    "                org_pred = q(org_feature)\n",
    "                flip_pred = q(flip_feature)\n",
    "                org_pred = torch.sigmoid(org_pred).squeeze(dim=-1).cpu().numpy() * 100    \n",
    "                flip_pred = torch.sigmoid(flip_pred).squeeze(dim=-1).cpu().numpy() * 100\n",
    "                pred = (org_pred + flip_pred)/2.\n",
    "                \n",
    "            val_score = mean_squared_error(val_df.Pawpularity, pred)**0.5\n",
    "            \n",
    "\n",
    "            #wandb.log({f'fold-{fold}-score' : val_score})\n",
    "                \n",
    "            early_stopper.check_early_stopping(loss=val_score)\n",
    "\n",
    "            if early_stopper.patience_counter == 0:\n",
    "                val_min_score = val_score\n",
    "                print(f'fold {fold} epoch {epoch} swin_score : {swin_score:.4f} val score : {val_score:.4f}', end = '\\r')\n",
    "                \n",
    "            if early_stopper.stop == True:\n",
    "                break\n",
    "                \n",
    "        trial.report(val_min_score, fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "                \n",
    "        val_scores.append(val_min_score)\n",
    "        print(f'fold {fold} epoch {epoch} swin_score : {swin_score:.4f} val score : {val_min_score:.4f}')\n",
    "    \n",
    "    cv_score = sum(val_scores)/len(val_scores)\n",
    "    \n",
    "    #scores = {f'fold_{k}':v for k, v in enumerate(val_scores)}\n",
    "    #scores['cv_score'] = cv_score\n",
    "    #wandb.log(scores)\n",
    "    \n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d501f5-4e94-4ede-a1b4-1cbd6d549dca",
   "metadata": {},
   "source": [
    "# Study Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5068ac0e-2ea0-4d97-965f-a1079a51e170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-04 02:41:54,483]\u001b[0m A new study created in memory with name: no-name-e8e2d62f-115b-412b-ba1b-ee6464646eab\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'objective' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7f637f7e5511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstudy_save_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{drive_root}/output/weights/final_weights/{model_code}_2nd_head/simple_head/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{study_save_dir}01-simple-head.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'objective' is not defined"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=1)\n",
    "study_save_dir = f'{drive_root}/output/weights/final_weights/{model_code}_2nd_head/simple_head/'\n",
    "\n",
    "with open(f\"{study_save_dir}01-simple-head.pkl\", 'wb') as file:\n",
    "    pickle.dump(study, file)\n",
    "\n",
    "trial = study.best_trial\n",
    "print(f\"Best trial:{trial.number}\")\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c2d23d-0970-48a8-8372-e0b539fa426b",
   "metadata": {},
   "source": [
    "# Train & Save Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de46029d-158e-4df8-a926-b8a77c383fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_save_dir = f'{drive_root}/output/weights/final_weights/{model_code}_2nd_head/simple_head/'\n",
    "\n",
    "with open(f\"{study_save_dir}01-simple-head.pkl\", 'rb') as file:\n",
    "    study = pickle.load(file)\n",
    "trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b9fde09-ca5a-4245-868b-49980afb25b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 epoch 95 swin_score : 17.6382 val score : 17.6555\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b4a223784c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# scalars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Set hyperparams\n",
    "\n",
    "config.optimizer.AdamW.lr = trial.params['learning_rate']\n",
    "config.model.h1 = trial.params['h1']\n",
    "config.model.h2 = trial.params['h2']\n",
    "config.patience =  trial.params['patience']\n",
    "config.model.activation = trial.params['activation']\n",
    "config.model.first_drop = trial.params['first_drop']\n",
    "config.model.second_drop = trial.params['second_drop']\n",
    "config.model.third_drop = trial.params['third_drop']\n",
    "\n",
    "beta1 = trial.params['beta1']\n",
    "beta2 = trial.params['beta2']\n",
    "config.optimizer.AdamW.betas = (beta1, beta2)\n",
    "config.optimizer.AdamW.weight_decay = trial.params['weight_decay']\n",
    "config.optimizer.AdamW.amsgrad = trial.params['amsgrad']\n",
    "config.scheduler.CosineAnnealingWarmRestarts.T_0 = trial.params['T_0']\n",
    "config.scheduler.CosineAnnealingWarmRestarts.T_mult = trial.params['T_mult']\n",
    "config.scheduler.CosineAnnealingWarmRestarts.eta_min = trial.params['eta_min']\n",
    "\n",
    "swin_scores=[]\n",
    "val_scores=[]\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_train[\"Id\"], df_train[\"Pawpularity\"])):\n",
    "\n",
    "    early_stopper = EarlyStopper(patience = config.patience, mode='min')\n",
    "    val_min_score = 1e+100\n",
    "\n",
    "    model_save_dir = f'{drive_root}/output/weights/final_weights/{model_code}/'\n",
    "    head_dir = f'{drive_root}/output/weights/final_weights/{model_code}_2nd_head/simple_head/SimpleHead_fold{fold}.ckpt'\n",
    "\n",
    "    train_df = df_train.loc[train_idx].reset_index(drop=True)\n",
    "    val_df = df_train.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    # Load embed features\n",
    "    val_predicts = np.load(f'{model_save_dir}val_predicts_fold{fold}.npy')\n",
    "    train_embed_features = np.load(f'{model_save_dir}train_embed_org_fold{fold}.npy')\n",
    "    val_embed_features = np.load(f'{model_save_dir}val_embed_org_fold{fold}.npy')\n",
    "    train_embed_flip_features = np.load(f'{model_save_dir}train_embed_flip_fold{fold}.npy')\n",
    "    val_embed_flip_features = np.load(f'{model_save_dir}val_embed_flip_fold{fold}.npy')\n",
    "    train_embed_merge_features = np.load(f'{model_save_dir}train_embed_merge_org_fold{fold}.npy')\n",
    "    val_embed_merge_features = np.load(f'{model_save_dir}val_embed_merge_org_fold{fold}.npy')\n",
    "    train_embed_merge_flip_features = np.load(f'{model_save_dir}train_embed_merge_flip_fold{fold}.npy')\n",
    "    val_embed_merge_flip_features = np.load(f'{model_save_dir}val_embed_merge_flip_fold{fold}.npy')\n",
    "    train_concat_features = np.concatenate((train_embed_merge_features, train_embed_merge_flip_features), axis=0)\n",
    "\n",
    "    train_loader = DataLoader(CustomDataset(train_concat_features, pd.concat([train_df['Pawpularity'], train_df['Pawpularity']]).reset_index(drop=True)), shuffle=config.train_loader.shuffle, batch_size=config.train_loader.batch_size)\n",
    "\n",
    "    # DataLoader\n",
    "    val_loader = DataLoader(CustomDataset(val_embed_features, val_df['Pawpularity']), shuffle=config.val_loader.shuffle, batch_size=config.val_loader.batch_size)\n",
    "\n",
    "    # Model\n",
    "    q = nn.Sequential(\n",
    "            nn.Dropout(config.model.first_drop), \n",
    "            nn.Linear(train_concat_features.shape[1], config.model.h1),\n",
    "            eval(config.model.activation)(),\n",
    "            nn.Dropout(config.model.second_drop), \n",
    "            nn.Linear(config.model.h1, config.model.h2),\n",
    "            eval(config.model.activation)(),\n",
    "            nn.Dropout(config.model.third_drop), \n",
    "            nn.Linear(config.model.h2, 1)).to('cuda')\n",
    "\n",
    "    # Optimizer & scheduler\n",
    "    optimizer = eval(config.optimizer.name)(q.parameters(), **config.optimizer.AdamW)\n",
    "    scheduler = eval(config.scheduler.name)(optimizer, **config.scheduler.CosineAnnealingWarmRestarts)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(config.epoch):\n",
    "\n",
    "        q.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for feature, label in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            feature, label = feature.to('cuda') , label.to('cuda')\n",
    "\n",
    "            pred = q(feature)\n",
    "\n",
    "            pred = pred.squeeze(dim=-1)\n",
    "\n",
    "            loss = criterion(pred.squeeze(dim=-1).float(), (label/100.).float())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        q.eval()\n",
    "        pred_lst = []\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            org_feature = torch.FloatTensor(val_embed_merge_features).to('cuda')\n",
    "            flip_feature = torch.FloatTensor(val_embed_merge_flip_features).to('cuda')\n",
    "            org_pred = q(org_feature)\n",
    "            flip_pred = q(flip_feature)\n",
    "            org_pred = torch.sigmoid(org_pred).squeeze(dim=-1).cpu().numpy() * 100    \n",
    "            flip_pred = torch.sigmoid(flip_pred).squeeze(dim=-1).cpu().numpy() * 100\n",
    "            pred = (org_pred + flip_pred)/2.\n",
    "\n",
    "        val_score = mean_squared_error(val_df.Pawpularity, pred)**0.5\n",
    "        swin_score = mean_squared_error(val_df.Pawpularity, val_predicts)**0.5\n",
    "\n",
    "        #wandb.log({f'fold-{fold}-score' : val_score})\n",
    "\n",
    "        early_stopper.check_early_stopping(loss=val_score)\n",
    "\n",
    "        if early_stopper.patience_counter == 0:\n",
    "            pickle.dump(q, open(head_dir, \"wb\"))\n",
    "            val_min_score = val_score\n",
    "            print(f'fold {fold} epoch {epoch} swin_score : {swin_score:.4f} val score : {val_score:.4f}', end = '\\r')\n",
    "\n",
    "        if early_stopper.stop == True:\n",
    "            break\n",
    "\n",
    "    val_scores.append(val_min_score)\n",
    "    print(f'fold {fold} epoch {epoch} swin_score : {swin_score:.2f} val score : {val_min_score:.2f}')\n",
    "\n",
    "cv_score = sum(val_scores)/len(val_scores)\n",
    "print(f'cv score : {cv_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a93a1322-ff57-4cd3-a92d-4abbaf35e31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 score : 17.500980781977002\n",
      "fold 1 score : 17.17985284488972\n",
      "fold 2 score : 17.065359825522936\n",
      "fold 3 score : 17.15248742051395\n",
      "fold 4 score : 17.077294456393087\n",
      "fold 5 score : 17.280627397404984\n",
      "fold 6 score : 17.74880500085912\n",
      "fold 7 score : 17.51049265301373\n",
      "fold 8 score : 18.01926757690769\n",
      "fold 9 score : 16.766728799891673\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_train[\"Id\"], df_train[\"Pawpularity\"])):\n",
    "    \n",
    "    early_stopper = EarlyStopper(patience = config.patience, mode='min')\n",
    "    val_min_score = 1e+100\n",
    "    \n",
    "    model_save_dir = f'{drive_root}/output/weights/final_weights/{model_code}/'\n",
    "    head_dir = f'{drive_root}/output/weights/final_weights/{model_code}/simple_head/SimpleHead_fold{fold}.ckpt'\n",
    "    result_save_dir = f'{drive_root}/output/weights/final_weights/{model_code}_2nd_head/simple_head/'\n",
    "    \n",
    "    train_df = df_train.loc[train_idx].reset_index(drop=True)\n",
    "    val_df = df_train.loc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # Load embed features\n",
    "    val_predicts = np.load(f'{model_save_dir}val_predicts_fold{fold}.npy')\n",
    "    val_embed_features = np.load(f'{model_save_dir}val_embed_org_fold{fold}.npy')\n",
    "    val_embed_flip_features = np.load(f'{model_save_dir}val_embed_flip_fold{fold}.npy')\n",
    "    val_embed_merge_features = np.load(f'{model_save_dir}val_embed_merge_org_fold{fold}.npy')\n",
    "    val_embed_merge_flip_features = np.load(f'{model_save_dir}val_embed_merge_flip_fold{fold}.npy')\n",
    "    \n",
    "    org_feature = torch.FloatTensor(val_embed_merge_features).to('cuda')\n",
    "    flip_feature = torch.FloatTensor(val_embed_merge_flip_features).to('cuda')\n",
    "    q = pickle.load(open(head_dir, \"rb\"))\n",
    "    q.eval()\n",
    "    with torch.no_grad():\n",
    "        org_pred = q(org_feature)\n",
    "        flip_pred = q(flip_feature)\n",
    "        org_pred = torch.sigmoid(org_pred).squeeze(dim=-1).cpu().numpy() * 100    \n",
    "        flip_pred = torch.sigmoid(flip_pred).squeeze(dim=-1).cpu().numpy() * 100\n",
    "        pred = (org_pred + flip_pred)/2.\n",
    "        \n",
    "    score = mean_squared_error(val_df.Pawpularity, pred)**0.5\n",
    "    print(f'fold {fold} score : {score}')\n",
    "    np.save(f'{result_save_dir}val_Simple_predicts{fold}.npy', pred)\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4827.079628,
   "end_time": "2021-11-28T14:45:21.922531",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-28T13:24:54.842903",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
